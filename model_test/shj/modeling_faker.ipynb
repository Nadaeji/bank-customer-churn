{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import TomekLinks, RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "random_state=51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CLIENTNUM",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Attrition_Flag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Customer_Age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Dependent_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Education_Level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Marital_Status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Income_Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Card_Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Months_on_book",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total_Relationship_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Months_Inactive_12_mon",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Contacts_Count_12_mon",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Credit_Limit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total_Revolving_Bal",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Avg_Open_To_Buy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total_Amt_Chng_Q4_Q1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total_Trans_Amt",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total_Trans_Ct",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total_Ct_Chng_Q4_Q1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Avg_Utilization_Ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6b5fae18-d911-40cb-a367-0e1bf986fe20",
       "rows": [
        [
         "0",
         "768805383",
         "Existing Customer",
         "45",
         "M",
         "3",
         "High School",
         "Married",
         "$60K - $80K",
         "Blue",
         "39",
         "5",
         "1",
         "3",
         "12691.0",
         "777",
         "11914.0",
         "1.335",
         "1144",
         "42",
         "1.625",
         "0.061",
         "9.3448e-05",
         "0.99991"
        ],
        [
         "1",
         "818770008",
         "Existing Customer",
         "49",
         "F",
         "5",
         "Graduate",
         "Single",
         "Less than $40K",
         "Blue",
         "44",
         "6",
         "1",
         "2",
         "8256.0",
         "864",
         "7392.0",
         "1.541",
         "1291",
         "33",
         "3.714",
         "0.105",
         "5.6861e-05",
         "0.99994"
        ],
        [
         "2",
         "713982108",
         "Existing Customer",
         "51",
         "M",
         "3",
         "Graduate",
         "Married",
         "$80K - $120K",
         "Blue",
         "36",
         "4",
         "1",
         "0",
         "3418.0",
         "0",
         "3418.0",
         "2.594",
         "1887",
         "20",
         "2.333",
         "0.0",
         "2.1081e-05",
         "0.99998"
        ],
        [
         "3",
         "769911858",
         "Existing Customer",
         "40",
         "F",
         "4",
         "High School",
         "Unknown",
         "Less than $40K",
         "Blue",
         "34",
         "3",
         "4",
         "1",
         "3313.0",
         "2517",
         "796.0",
         "1.405",
         "1171",
         "20",
         "2.333",
         "0.76",
         "0.00013366",
         "0.99987"
        ],
        [
         "4",
         "709106358",
         "Existing Customer",
         "40",
         "M",
         "3",
         "Uneducated",
         "Married",
         "$60K - $80K",
         "Blue",
         "21",
         "5",
         "1",
         "0",
         "4716.0",
         "0",
         "4716.0",
         "2.175",
         "816",
         "28",
         "2.5",
         "0.0",
         "2.1676e-05",
         "0.99998"
        ],
        [
         "5",
         "713061558",
         "Existing Customer",
         "44",
         "M",
         "2",
         "Graduate",
         "Married",
         "$40K - $60K",
         "Blue",
         "36",
         "3",
         "1",
         "2",
         "4010.0",
         "1247",
         "2763.0",
         "1.376",
         "1088",
         "24",
         "0.846",
         "0.311",
         "5.5077e-05",
         "0.99994"
        ],
        [
         "6",
         "810347208",
         "Existing Customer",
         "51",
         "M",
         "4",
         "Unknown",
         "Married",
         "$120K +",
         "Gold",
         "46",
         "6",
         "1",
         "3",
         "34516.0",
         "2264",
         "32252.0",
         "1.975",
         "1330",
         "31",
         "0.722",
         "0.066",
         "0.00012303",
         "0.99988"
        ],
        [
         "7",
         "818906208",
         "Existing Customer",
         "32",
         "M",
         "0",
         "High School",
         "Unknown",
         "$60K - $80K",
         "Silver",
         "27",
         "2",
         "2",
         "2",
         "29081.0",
         "1396",
         "27685.0",
         "2.204",
         "1538",
         "36",
         "0.714",
         "0.048",
         "8.5795e-05",
         "0.99991"
        ],
        [
         "8",
         "710930508",
         "Existing Customer",
         "37",
         "M",
         "3",
         "Uneducated",
         "Single",
         "$60K - $80K",
         "Blue",
         "36",
         "5",
         "2",
         "0",
         "22352.0",
         "2517",
         "19835.0",
         "3.355",
         "1350",
         "24",
         "1.182",
         "0.113",
         "4.4796e-05",
         "0.99996"
        ],
        [
         "9",
         "719661558",
         "Existing Customer",
         "48",
         "M",
         "2",
         "Graduate",
         "Single",
         "$80K - $120K",
         "Blue",
         "36",
         "6",
         "3",
         "3",
         "11656.0",
         "1677",
         "9979.0",
         "1.524",
         "1441",
         "32",
         "0.882",
         "0.144",
         "0.00030251",
         "0.9997"
        ],
        [
         "10",
         "708790833",
         "Existing Customer",
         "42",
         "M",
         "5",
         "Uneducated",
         "Unknown",
         "$120K +",
         "Blue",
         "31",
         "5",
         "3",
         "2",
         "6748.0",
         "1467",
         "5281.0",
         "0.831",
         "1201",
         "42",
         "0.68",
         "0.217",
         "0.00019094",
         "0.99981"
        ],
        [
         "11",
         "710821833",
         "Existing Customer",
         "65",
         "M",
         "1",
         "Unknown",
         "Married",
         "$40K - $60K",
         "Blue",
         "54",
         "6",
         "2",
         "3",
         "9095.0",
         "1587",
         "7508.0",
         "1.433",
         "1314",
         "26",
         "1.364",
         "0.174",
         "0.00019751",
         "0.9998"
        ],
        [
         "12",
         "710599683",
         "Existing Customer",
         "56",
         "M",
         "1",
         "College",
         "Single",
         "$80K - $120K",
         "Blue",
         "36",
         "3",
         "6",
         "0",
         "11751.0",
         "0",
         "11751.0",
         "3.397",
         "1539",
         "17",
         "3.25",
         "0.0",
         "4.7799e-05",
         "0.99995"
        ],
        [
         "13",
         "816082233",
         "Existing Customer",
         "35",
         "M",
         "3",
         "Graduate",
         "Unknown",
         "$60K - $80K",
         "Blue",
         "30",
         "5",
         "1",
         "3",
         "8547.0",
         "1666",
         "6881.0",
         "1.163",
         "1311",
         "33",
         "2.0",
         "0.195",
         "9.6126e-05",
         "0.9999"
        ],
        [
         "14",
         "712396908",
         "Existing Customer",
         "57",
         "F",
         "2",
         "Graduate",
         "Married",
         "Less than $40K",
         "Blue",
         "48",
         "5",
         "2",
         "2",
         "2436.0",
         "680",
         "1756.0",
         "1.19",
         "1570",
         "29",
         "0.611",
         "0.279",
         "0.00011382",
         "0.99989"
        ],
        [
         "15",
         "714885258",
         "Existing Customer",
         "44",
         "M",
         "4",
         "Unknown",
         "Unknown",
         "$80K - $120K",
         "Blue",
         "37",
         "5",
         "1",
         "2",
         "4234.0",
         "972",
         "3262.0",
         "1.707",
         "1348",
         "27",
         "1.7",
         "0.23",
         "6.3492e-05",
         "0.99994"
        ],
        [
         "16",
         "709967358",
         "Existing Customer",
         "48",
         "M",
         "4",
         "Post-Graduate",
         "Single",
         "$80K - $120K",
         "Blue",
         "36",
         "6",
         "2",
         "3",
         "30367.0",
         "2362",
         "28005.0",
         "1.708",
         "1671",
         "27",
         "0.929",
         "0.078",
         "0.00023623",
         "0.99976"
        ],
        [
         "17",
         "753327333",
         "Existing Customer",
         "41",
         "M",
         "3",
         "Unknown",
         "Married",
         "$80K - $120K",
         "Blue",
         "34",
         "4",
         "4",
         "1",
         "13535.0",
         "1291",
         "12244.0",
         "0.653",
         "1028",
         "21",
         "1.625",
         "0.095",
         "0.00014953",
         "0.99985"
        ],
        [
         "18",
         "806160108",
         "Existing Customer",
         "61",
         "M",
         "1",
         "High School",
         "Married",
         "$40K - $60K",
         "Blue",
         "56",
         "2",
         "2",
         "3",
         "3193.0",
         "2517",
         "676.0",
         "1.831",
         "1336",
         "30",
         "1.143",
         "0.788",
         "0.00017468",
         "0.99983"
        ],
        [
         "19",
         "709327383",
         "Existing Customer",
         "45",
         "F",
         "2",
         "Graduate",
         "Married",
         "Unknown",
         "Blue",
         "37",
         "6",
         "1",
         "2",
         "14470.0",
         "1157",
         "13313.0",
         "0.966",
         "1207",
         "21",
         "0.909",
         "0.08",
         "5.5077e-05",
         "0.99994"
        ],
        [
         "20",
         "806165208",
         "Existing Customer",
         "47",
         "M",
         "1",
         "Doctorate",
         "Divorced",
         "$60K - $80K",
         "Blue",
         "42",
         "5",
         "2",
         "0",
         "20979.0",
         "1800",
         "19179.0",
         "0.906",
         "1178",
         "27",
         "0.929",
         "0.086",
         "5.703e-05",
         "0.99994"
        ],
        [
         "21",
         "708508758",
         "Attrited Customer",
         "62",
         "F",
         "0",
         "Graduate",
         "Married",
         "Less than $40K",
         "Blue",
         "49",
         "2",
         "3",
         "3",
         "1438.3",
         "0",
         "1438.3",
         "1.047",
         "692",
         "16",
         "0.6",
         "0.0",
         "0.99616",
         "0.0038363"
        ],
        [
         "22",
         "784725333",
         "Existing Customer",
         "41",
         "M",
         "3",
         "High School",
         "Married",
         "$40K - $60K",
         "Blue",
         "33",
         "4",
         "2",
         "1",
         "4470.0",
         "680",
         "3790.0",
         "1.608",
         "931",
         "18",
         "1.571",
         "0.152",
         "6.9242e-05",
         "0.99993"
        ],
        [
         "23",
         "811604133",
         "Existing Customer",
         "47",
         "F",
         "4",
         "Unknown",
         "Single",
         "Less than $40K",
         "Blue",
         "36",
         "3",
         "3",
         "2",
         "2492.0",
         "1560",
         "932.0",
         "0.573",
         "1126",
         "23",
         "0.353",
         "0.626",
         "0.00020735",
         "0.99979"
        ],
        [
         "24",
         "789124683",
         "Existing Customer",
         "54",
         "M",
         "2",
         "Unknown",
         "Married",
         "$80K - $120K",
         "Blue",
         "42",
         "4",
         "2",
         "3",
         "12217.0",
         "0",
         "12217.0",
         "1.075",
         "1110",
         "21",
         "0.75",
         "0.0",
         "0.00021042",
         "0.99979"
        ],
        [
         "25",
         "771071958",
         "Existing Customer",
         "41",
         "F",
         "3",
         "Graduate",
         "Single",
         "Less than $40K",
         "Blue",
         "28",
         "6",
         "1",
         "2",
         "7768.0",
         "1669",
         "6099.0",
         "0.797",
         "1051",
         "22",
         "0.833",
         "0.215",
         "5.7151e-05",
         "0.99994"
        ],
        [
         "26",
         "720466383",
         "Existing Customer",
         "59",
         "M",
         "1",
         "High School",
         "Unknown",
         "$40K - $60K",
         "Blue",
         "46",
         "4",
         "1",
         "2",
         "14784.0",
         "1374",
         "13410.0",
         "0.921",
         "1197",
         "23",
         "1.3",
         "0.093",
         "5.0256e-05",
         "0.99995"
        ],
        [
         "27",
         "804424383",
         "Existing Customer",
         "63",
         "M",
         "1",
         "Unknown",
         "Married",
         "$60K - $80K",
         "Blue",
         "56",
         "3",
         "3",
         "2",
         "10215.0",
         "1010",
         "9205.0",
         "0.843",
         "1904",
         "40",
         "1.0",
         "0.099",
         "0.00018558",
         "0.99981"
        ],
        [
         "28",
         "718813833",
         "Existing Customer",
         "44",
         "F",
         "3",
         "Uneducated",
         "Single",
         "Unknown",
         "Blue",
         "34",
         "5",
         "2",
         "2",
         "10100.0",
         "0",
         "10100.0",
         "0.525",
         "1052",
         "18",
         "1.571",
         "0.0",
         "0.00012144",
         "0.99988"
        ],
        [
         "29",
         "806624208",
         "Existing Customer",
         "47",
         "M",
         "4",
         "High School",
         "Married",
         "$40K - $60K",
         "Blue",
         "42",
         "6",
         "0",
         "0",
         "4785.0",
         "1362",
         "3423.0",
         "0.739",
         "1045",
         "38",
         "0.9",
         "0.285",
         "7.6642e-06",
         "0.99999"
        ],
        [
         "30",
         "778348233",
         "Existing Customer",
         "53",
         "M",
         "3",
         "Unknown",
         "Married",
         "$80K - $120K",
         "Blue",
         "33",
         "3",
         "2",
         "3",
         "2753.0",
         "1811",
         "942.0",
         "0.977",
         "1038",
         "25",
         "2.571",
         "0.658",
         "0.00021834",
         "0.99978"
        ],
        [
         "31",
         "712991808",
         "Existing Customer",
         "53",
         "M",
         "2",
         "Uneducated",
         "Married",
         "$60K - $80K",
         "Blue",
         "48",
         "2",
         "5",
         "1",
         "2451.0",
         "1690",
         "761.0",
         "1.323",
         "1596",
         "26",
         "1.6",
         "0.69",
         "0.00012458",
         "0.99988"
        ],
        [
         "32",
         "709029408",
         "Existing Customer",
         "41",
         "M",
         "4",
         "Graduate",
         "Married",
         "$60K - $80K",
         "Blue",
         "36",
         "4",
         "1",
         "2",
         "8923.0",
         "2517",
         "6406.0",
         "1.726",
         "1589",
         "24",
         "1.667",
         "0.282",
         "5.7762e-05",
         "0.99994"
        ],
        [
         "33",
         "788658483",
         "Existing Customer",
         "53",
         "F",
         "2",
         "College",
         "Married",
         "Less than $40K",
         "Blue",
         "38",
         "5",
         "2",
         "3",
         "2650.0",
         "1490",
         "1160.0",
         "1.75",
         "1411",
         "28",
         "1.0",
         "0.562",
         "0.00018612",
         "0.99981"
        ],
        [
         "34",
         "787937058",
         "Existing Customer",
         "58",
         "M",
         "0",
         "Graduate",
         "Married",
         "$80K - $120K",
         "Blue",
         "49",
         "6",
         "2",
         "2",
         "12555.0",
         "1696",
         "10859.0",
         "0.519",
         "1291",
         "24",
         "0.714",
         "0.135",
         "9.7673e-05",
         "0.9999"
        ],
        [
         "35",
         "715318008",
         "Existing Customer",
         "55",
         "F",
         "1",
         "College",
         "Single",
         "Less than $40K",
         "Blue",
         "36",
         "4",
         "2",
         "1",
         "3520.0",
         "1914",
         "1606.0",
         "0.51",
         "1407",
         "43",
         "0.483",
         "0.544",
         "6.2639e-05",
         "0.99994"
        ],
        [
         "36",
         "713962233",
         "Existing Customer",
         "55",
         "F",
         "3",
         "Graduate",
         "Married",
         "Less than $40K",
         "Blue",
         "36",
         "6",
         "2",
         "3",
         "3035.0",
         "2298",
         "737.0",
         "1.724",
         "1877",
         "37",
         "1.176",
         "0.757",
         "0.00019864",
         "0.9998"
        ],
        [
         "37",
         "785432733",
         "Existing Customer",
         "42",
         "F",
         "4",
         "High School",
         "Married",
         "Less than $40K",
         "Gold",
         "36",
         "2",
         "3",
         "3",
         "15433.0",
         "0",
         "15433.0",
         "0.865",
         "966",
         "22",
         "1.2",
         "0.0",
         "0.00035532",
         "0.99964"
        ],
        [
         "38",
         "715190283",
         "Existing Customer",
         "57",
         "F",
         "1",
         "Graduate",
         "Unknown",
         "$40K - $60K",
         "Blue",
         "49",
         "3",
         "3",
         "2",
         "3672.0",
         "886",
         "2786.0",
         "1.32",
         "1464",
         "28",
         "0.556",
         "0.241",
         "0.00016883",
         "0.99983"
        ],
        [
         "39",
         "708300483",
         "Attrited Customer",
         "66",
         "F",
         "0",
         "Doctorate",
         "Married",
         "Unknown",
         "Blue",
         "56",
         "5",
         "4",
         "3",
         "7882.0",
         "605",
         "7277.0",
         "1.052",
         "704",
         "16",
         "0.143",
         "0.077",
         "0.9978",
         "0.00219708"
        ],
        [
         "40",
         "827111283",
         "Existing Customer",
         "45",
         "M",
         "3",
         "Graduate",
         "Single",
         "$80K - $120K",
         "Blue",
         "41",
         "2",
         "2",
         "2",
         "32426.0",
         "578",
         "31848.0",
         "1.042",
         "1109",
         "28",
         "0.474",
         "0.018",
         "0.00011811",
         "0.99988"
        ],
        [
         "41",
         "758551608",
         "Existing Customer",
         "51",
         "M",
         "2",
         "Unknown",
         "Married",
         "$40K - $60K",
         "Blue",
         "44",
         "4",
         "1",
         "0",
         "6205.0",
         "2204",
         "4001.0",
         "0.803",
         "1347",
         "28",
         "0.556",
         "0.355",
         "2.2331e-05",
         "0.99998"
        ],
        [
         "42",
         "773146383",
         "Existing Customer",
         "50",
         "F",
         "1",
         "College",
         "Single",
         "$40K - $60K",
         "Silver",
         "43",
         "3",
         "2",
         "3",
         "17304.0",
         "2517",
         "14787.0",
         "1.449",
         "1756",
         "33",
         "1.2",
         "0.145",
         "0.00015785",
         "0.99984"
        ],
        [
         "43",
         "778493808",
         "Existing Customer",
         "49",
         "M",
         "3",
         "High School",
         "Married",
         "$60K - $80K",
         "Blue",
         "37",
         "5",
         "2",
         "1",
         "3906.0",
         "0",
         "3906.0",
         "1.214",
         "1756",
         "32",
         "1.0",
         "0.0",
         "6.9242e-05",
         "0.99993"
        ],
        [
         "44",
         "720572508",
         "Existing Customer",
         "38",
         "F",
         "4",
         "Graduate",
         "Single",
         "Unknown",
         "Blue",
         "28",
         "2",
         "3",
         "3",
         "9830.0",
         "2055",
         "7775.0",
         "0.977",
         "1042",
         "23",
         "0.917",
         "0.209",
         "0.00031726",
         "0.99968"
        ],
        [
         "45",
         "712661433",
         "Existing Customer",
         "49",
         "M",
         "4",
         "Uneducated",
         "Single",
         "$80K - $120K",
         "Blue",
         "30",
         "3",
         "2",
         "3",
         "34516.0",
         "0",
         "34516.0",
         "1.621",
         "1444",
         "28",
         "1.333",
         "0.0",
         "0.00020643",
         "0.99979"
        ],
        [
         "46",
         "789172683",
         "Existing Customer",
         "56",
         "M",
         "2",
         "Doctorate",
         "Married",
         "$60K - $80K",
         "Blue",
         "45",
         "6",
         "2",
         "0",
         "2283.0",
         "1430",
         "853.0",
         "2.316",
         "1741",
         "27",
         "0.588",
         "0.626",
         "6.0759e-05",
         "0.99994"
        ],
        [
         "47",
         "738406533",
         "Existing Customer",
         "59",
         "M",
         "1",
         "Doctorate",
         "Married",
         "$40K - $60K",
         "Blue",
         "52",
         "3",
         "2",
         "2",
         "2548.0",
         "2020",
         "528.0",
         "2.357",
         "1719",
         "27",
         "1.7",
         "0.793",
         "0.0001546",
         "0.99985"
        ],
        [
         "48",
         "799723908",
         "Existing Customer",
         "46",
         "M",
         "3",
         "High School",
         "Married",
         "$80K - $120K",
         "Blue",
         "40",
         "4",
         "3",
         "3",
         "19458.0",
         "1435",
         "18023.0",
         "0.787",
         "1217",
         "27",
         "0.8",
         "0.074",
         "0.00030516",
         "0.99969"
        ],
        [
         "49",
         "771490833",
         "Existing Customer",
         "52",
         "M",
         "1",
         "College",
         "Single",
         "$80K - $120K",
         "Blue",
         "40",
         "5",
         "1",
         "1",
         "4745.0",
         "1227",
         "3518.0",
         "0.624",
         "1140",
         "40",
         "0.6",
         "0.259",
         "3.031e-05",
         "0.99997"
        ]
       ],
       "shape": {
        "columns": 23,
        "rows": 10127
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.999910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>818770008</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.999940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713982108</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769911858</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.999870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709106358</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>772366833</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1851</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>15476</td>\n",
       "      <td>117</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>710638233</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>2186</td>\n",
       "      <td>2091.0</td>\n",
       "      <td>0.804</td>\n",
       "      <td>8764</td>\n",
       "      <td>69</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.995270</td>\n",
       "      <td>0.004729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>716506083</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5409.0</td>\n",
       "      <td>0.819</td>\n",
       "      <td>10291</td>\n",
       "      <td>60</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.997880</td>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>717406983</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0.535</td>\n",
       "      <td>8395</td>\n",
       "      <td>62</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>0.003294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>714337233</td>\n",
       "      <td>Attrited Customer</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Silver</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>10388.0</td>\n",
       "      <td>1961</td>\n",
       "      <td>8427.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>10294</td>\n",
       "      <td>61</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.996620</td>\n",
       "      <td>0.003377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0      768805383  Existing Customer            45      M                3   \n",
       "1      818770008  Existing Customer            49      F                5   \n",
       "2      713982108  Existing Customer            51      M                3   \n",
       "3      769911858  Existing Customer            40      F                4   \n",
       "4      709106358  Existing Customer            40      M                3   \n",
       "...          ...                ...           ...    ...              ...   \n",
       "10122  772366833  Existing Customer            50      M                2   \n",
       "10123  710638233  Attrited Customer            41      M                2   \n",
       "10124  716506083  Attrited Customer            44      F                1   \n",
       "10125  717406983  Attrited Customer            30      M                2   \n",
       "10126  714337233  Attrited Customer            43      F                2   \n",
       "\n",
       "      Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0         High School        Married     $60K - $80K          Blue   \n",
       "1            Graduate         Single  Less than $40K          Blue   \n",
       "2            Graduate        Married    $80K - $120K          Blue   \n",
       "3         High School        Unknown  Less than $40K          Blue   \n",
       "4          Uneducated        Married     $60K - $80K          Blue   \n",
       "...               ...            ...             ...           ...   \n",
       "10122        Graduate         Single     $40K - $60K          Blue   \n",
       "10123         Unknown       Divorced     $40K - $60K          Blue   \n",
       "10124     High School        Married  Less than $40K          Blue   \n",
       "10125        Graduate        Unknown     $40K - $60K          Blue   \n",
       "10126        Graduate        Married  Less than $40K        Silver   \n",
       "\n",
       "       Months_on_book  ...  Credit_Limit  Total_Revolving_Bal  \\\n",
       "0                  39  ...       12691.0                  777   \n",
       "1                  44  ...        8256.0                  864   \n",
       "2                  36  ...        3418.0                    0   \n",
       "3                  34  ...        3313.0                 2517   \n",
       "4                  21  ...        4716.0                    0   \n",
       "...               ...  ...           ...                  ...   \n",
       "10122              40  ...        4003.0                 1851   \n",
       "10123              25  ...        4277.0                 2186   \n",
       "10124              36  ...        5409.0                    0   \n",
       "10125              36  ...        5281.0                    0   \n",
       "10126              25  ...       10388.0                 1961   \n",
       "\n",
       "       Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "0              11914.0                 1.335             1144              42   \n",
       "1               7392.0                 1.541             1291              33   \n",
       "2               3418.0                 2.594             1887              20   \n",
       "3                796.0                 1.405             1171              20   \n",
       "4               4716.0                 2.175              816              28   \n",
       "...                ...                   ...              ...             ...   \n",
       "10122           2152.0                 0.703            15476             117   \n",
       "10123           2091.0                 0.804             8764              69   \n",
       "10124           5409.0                 0.819            10291              60   \n",
       "10125           5281.0                 0.535             8395              62   \n",
       "10126           8427.0                 0.703            10294              61   \n",
       "\n",
       "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \\\n",
       "0                    1.625                  0.061   \n",
       "1                    3.714                  0.105   \n",
       "2                    2.333                  0.000   \n",
       "3                    2.333                  0.760   \n",
       "4                    2.500                  0.000   \n",
       "...                    ...                    ...   \n",
       "10122                0.857                  0.462   \n",
       "10123                0.683                  0.511   \n",
       "10124                0.818                  0.000   \n",
       "10125                0.722                  0.000   \n",
       "10126                0.649                  0.189   \n",
       "\n",
       "       Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  \\\n",
       "0                                               0.000093                                                                                    \n",
       "1                                               0.000057                                                                                    \n",
       "2                                               0.000021                                                                                    \n",
       "3                                               0.000134                                                                                    \n",
       "4                                               0.000022                                                                                    \n",
       "...                                                  ...                                                                                    \n",
       "10122                                           0.000191                                                                                    \n",
       "10123                                           0.995270                                                                                    \n",
       "10124                                           0.997880                                                                                    \n",
       "10125                                           0.996710                                                                                    \n",
       "10126                                           0.996620                                                                                    \n",
       "\n",
       "       Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  \n",
       "0                                               0.999910                                                                                   \n",
       "1                                               0.999940                                                                                   \n",
       "2                                               0.999980                                                                                   \n",
       "3                                               0.999870                                                                                   \n",
       "4                                               0.999980                                                                                   \n",
       "...                                                  ...                                                                                   \n",
       "10122                                           0.999810                                                                                   \n",
       "10123                                           0.004729                                                                                   \n",
       "10124                                           0.002118                                                                                   \n",
       "10125                                           0.003294                                                                                   \n",
       "10126                                           0.003377                                                                                   \n",
       "\n",
       "[10127 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "bank_df = pd.read_csv('../../data/BankChurners.csv')\n",
    "bank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없는 칼럼 제거\n",
    "drop_columns = ['CLIENTNUM',\n",
    "                'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
    "                'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2',\n",
    "                                \n",
    "                # 'Total_Trans_Amt',\n",
    "                'Total_Trans_Ct',\n",
    "                'Total_Relationship_Count',\n",
    "                'Total_Revolving_Bal',                \n",
    "                'Total_Amt_Chng_Q4_Q1',\n",
    "                'Total_Ct_Chng_Q4_Q1'\n",
    "]\n",
    "bank_df = bank_df.drop(columns=drop_columns)\n",
    "\n",
    "# bank_df = bank_df.loc[:, ~bank_df.columns.str.startswith(\"Total_\")]\n",
    "\n",
    "# 이탈여부 값 변환\n",
    "bank_df['Attrition_Flag'] = bank_df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 칼럼\n",
    "cate_columns = ['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\n",
    "\n",
    "# 원핫 인코딩\n",
    "encoder = OneHotEncoder()\n",
    "encoded_cate = encoder.fit_transform(bank_df[cate_columns]).toarray()\n",
    "encoded_cate_df = pd.DataFrame(data=encoded_cate, columns=encoder.get_feature_names_out(cate_columns))\n",
    "\n",
    "# 원래 데이터에서 범주형 칼럼 제거\n",
    "bank_df = bank_df.drop(columns=cate_columns)\n",
    "\n",
    "# 인코딩된 데이터와 결합\n",
    "bank_df = pd.concat([bank_df, encoded_cate_df], axis=1)\n",
    "\n",
    "# display(bank_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 & 평가 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 0\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.82      0.77      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.93      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97736256 0.97736256 0.97560976 0.97769784 0.97736256]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1701\n",
      "           1       0.83      0.80      0.82       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.88      0.89      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 1\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.72      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97835498 0.97631012 0.97701149 0.972103   0.98194946]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.78      0.79      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.88      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 2\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.74      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97445124 0.97947425 0.97631012 0.98087333 0.97073519]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.77      0.77      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 3\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1701\n",
      "           1       0.86      0.74      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.91      0.86      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97589061 0.97525995 0.97771387 0.98122744 0.97525995]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.78      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 4\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.77      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97766571 0.97947425 0.97525995 0.97806544 0.97699497]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.77      0.81      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.88      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 5\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.76      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97768179 0.97631012 0.97525995 0.97875405 0.97560976]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.77      0.81      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.88      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 6\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.72      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97731365 0.97736256 0.97631012 0.98193642 0.97701149]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1701\n",
      "           1       0.77      0.72      0.74       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.86      0.84      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 7\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.74      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97590795 0.9724705  0.98124098 0.98335745 0.97525995]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1701\n",
      "           1       0.78      0.74      0.76       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.86      0.85      0.86      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 8\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.72      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97622478 0.97631012 0.97736256 0.97840173 0.97841727]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 9\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.74      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.9748924  0.97876934 0.97806544 0.9734957  0.97525995]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.77      0.77      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 10\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.79      0.74      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.85      0.86      2026\n",
      "weighted avg       0.92      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97266187 0.97560976 0.98018018 0.97736256 0.98264642]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1701\n",
      "           1       0.75      0.76      0.75       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.85      0.85      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 11\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1701\n",
      "           1       0.85      0.75      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.86      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97728092 0.97525995 0.97560976 0.97594255 0.97806544]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.77      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 12\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.72      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.6}\n",
      "Cross Val Score : [0.9762419  0.97491039 0.97771387 0.98016589 0.97525995]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.79      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 13\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.82      0.78      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97840173 0.97421203 0.98018018 0.97769784 0.97386323]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.77      0.82      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.88      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 14\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.80      0.72      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.84      0.86      2026\n",
      "weighted avg       0.92      0.93      0.92      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.9748924  0.97806544 0.97666068 0.97734628 0.97841727]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1701\n",
      "           1       0.76      0.72      0.74       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.85      0.84      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 15\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.73      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97552196 0.97947425 0.97595981 0.9762931  0.97806544]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.81      0.79      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.88      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 16\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1701\n",
      "           1       0.86      0.73      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.85      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97589061 0.97701149 0.97947425 0.97734628 0.97631012]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.82      0.78      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 17\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.74      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.98049133 0.97212294 0.97947425 0.97945946 0.97421203]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1701\n",
      "           1       0.74      0.77      0.75       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.85      0.86      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 18\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.72      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97373156 0.97736256 0.98124098 0.98016589 0.97701149]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.79      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.88      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 19\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.73      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.90      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.9762419  0.97701149 0.97456109 0.97910663 0.97631012]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 20\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.80      0.73      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97343862 0.97912167 0.97560976 0.97876934 0.97910663]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.77      0.77      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 21\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.84      0.76      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.98226565 0.97947425 0.97142857 0.97664391 0.97841727]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.78      0.79      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 22\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.74      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.86      0.87      2026\n",
      "weighted avg       0.93      0.94      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.96820293 0.97841727 0.97421203 0.97769784 0.98018018]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.79      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.88      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 23\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.71      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97517092 0.97595981 0.98053353 0.97594255 0.98053353]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.79      0.76      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 24\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.75      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97375045 0.97771387 0.97491039 0.97910663 0.98230408]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.77      0.78      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 25\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.72      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97945946 0.97525995 0.98018018 0.97875405 0.97666068]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.78      0.76      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 26\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.75      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97241132 0.98018018 0.97560976 0.97875405 0.97560976]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.77      0.78      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 27\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.72      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.6}\n",
      "Cross Val Score : [0.98015157 0.97666068 0.97771387 0.97945946 0.97421203]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.78      0.75      0.76       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.86      0.85      0.86      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 28\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.83      0.77      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97231212 0.97701149 0.97595981 0.98336949 0.97804966]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.78      0.81      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.88      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 29\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.72      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97589061 0.97947425 0.98159509 0.9762931  0.9724705 ]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.80      0.74      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 30\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.80      0.74      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97056712 0.97631012 0.98194946 0.9762931  0.97771387]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.77      0.77      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 31\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.74      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.86      0.88      2026\n",
      "weighted avg       0.93      0.94      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97515304 0.97912167 0.97595981 0.97664391 0.97912167]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.80      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.88      0.88      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 32\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.80      0.74      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.98226565 0.97281831 0.97666068 0.97840173 0.97595981]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.77      0.77      0.77       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 33\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.74      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.9762419  0.98336949 0.97525995 0.97525995 0.97419355]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.77      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 34\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.72      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97585586 0.97947425 0.97142857 0.97840173 0.97560976]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.78      0.75      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 35\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.72      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Cross Val Score : [0.98015157 0.97560976 0.97631012 0.97314715 0.97806544]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.79      0.76      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 36\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.73      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97620764 0.97701149 0.98018018 0.98051948 0.97595981]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 37\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.83      0.77      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97838617 0.97525995 0.97421203 0.9762931  0.98194946]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.81      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.88      0.87      0.88      2026\n",
      "weighted avg       0.93      0.94      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 38\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1701\n",
      "           1       0.81      0.70      0.75       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.88      0.83      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.9738445  0.97701149 0.98301409 0.97875405 0.97841727]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1701\n",
      "           1       0.76      0.74      0.75       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.86      0.85      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 39\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.71      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.84      0.86      2026\n",
      "weighted avg       0.92      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.98007968 0.97841727 0.9724705  0.97804966 0.97631012]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.79      0.73      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.85      0.86      2026\n",
      "weighted avg       0.92      0.93      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 40\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1701\n",
      "           1       0.79      0.72      0.75       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.87      0.84      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97308934 0.97841727 0.98194946 0.98229129 0.97316637]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.78      0.76      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 41\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.85      0.75      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.86      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97517092 0.98159509 0.98018018 0.97804966 0.96935139]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.78      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 42\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1701\n",
      "           1       0.85      0.70      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.90      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97032535 0.97701149 0.97771387 0.97945946 0.97841727]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.81      0.77      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 43\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.71      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97691198 0.97736256 0.98124098 0.97734628 0.97631012]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.75      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 44\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      1701\n",
      "           1       0.79      0.70      0.74       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.87      0.83      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97909156 0.98018018 0.97595981 0.9762931  0.98088713]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.80      0.72      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.84      0.86      2026\n",
      "weighted avg       0.92      0.93      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 45\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1701\n",
      "           1       0.81      0.70      0.75       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.84      0.85      2026\n",
      "weighted avg       0.92      0.93      0.92      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97589061 0.97595981 0.97736256 0.9815818  0.97525995]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.78      0.77      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 46\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.74      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97838617 0.98053353 0.97421203 0.9734957  0.97806544]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.79      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.88      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 47\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.85      0.73      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.85      0.87      2026\n",
      "weighted avg       0.93      0.94      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97687861 0.97281831 0.98265896 0.97701149 0.9748924 ]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.79      0.76      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 48\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.77      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97202296 0.98159509 0.97736256 0.97279885 0.97631012]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.75      0.80      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.88      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 49\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.80      0.73      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.85      0.86      2026\n",
      "weighted avg       0.92      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97975416 0.97038887 0.97806544 0.98229129 0.97525995]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      1701\n",
      "           1       0.75      0.77      0.76       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.85      0.86      0.86      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 50\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.73      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97734628 0.97281831 0.97491039 0.98087333 0.98088713]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 51\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      1701\n",
      "           1       0.86      0.76      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.91      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97060932 0.97841727 0.97736256 0.97840173 0.96900606]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1701\n",
      "           1       0.82      0.82      0.82       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.89      0.89      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 52\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.72      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97723166 0.97947425 0.98053353 0.97314715 0.97595981]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.78      0.74      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.85      0.86      2026\n",
      "weighted avg       0.92      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 53\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.71      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97419355 0.97666068 0.97386323 0.97840173 0.97525995]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.77      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 54\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.73      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97376931 0.97806544 0.97841727 0.97736256 0.98122744]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.76      0.78      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 55\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.80      0.75      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97940007 0.97947425 0.97947425 0.9762931  0.97947425]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.79      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.88      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 56\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.80      0.75      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.96827094 0.97806544 0.98088713 0.97945946 0.97912167]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.77      0.80      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.88      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 57\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.73      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.90      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97443284 0.97701149 0.97947425 0.97594255 0.97701149]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.77      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 58\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1701\n",
      "           1       0.87      0.72      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.91      0.85      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.9752422  0.97841727 0.97736256 0.97945946 0.97595981]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.83      0.78      0.81       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.88      0.89      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 59\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.73      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.96995708 0.97841727 0.97631012 0.97734628 0.98265896]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 60\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.73      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97833935 0.98408104 0.98124098 0.97140815 0.97316637]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 61\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.75      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97901592 0.97841727 0.97177563 0.97804966 0.97841727]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.78      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 62\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.76      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97515304 0.97456109 0.97666068 0.98406951 0.97560976]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      1701\n",
      "           1       0.75      0.77      0.76       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.85      0.86      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 63\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.81      0.77      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97620764 0.98159509 0.97421203 0.9748924  0.98124098]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.76      0.79      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 64\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1701\n",
      "           1       0.86      0.75      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.86      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97763348 0.97421203 0.97771387 0.98229129 0.97108176]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1701\n",
      "           1       0.82      0.82      0.82       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.89      0.89      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 65\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.74      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.86      0.87      2026\n",
      "weighted avg       0.93      0.94      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97589061 0.98124098 0.97771387 0.9734957  0.97701149]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.78      0.77      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 66\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1701\n",
      "           1       0.86      0.77      0.81       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.91      0.87      0.89      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97691198 0.9700428  0.98159509 0.97769784 0.97316637]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.81      0.77      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 67\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.74      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97206304 0.98194946 0.97701149 0.97804966 0.97701149]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 68\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.83      0.77      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.9696537  0.97841727 0.97771387 0.97525995 0.97875405]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1701\n",
      "           1       0.77      0.82      0.80       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.89      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 69\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.80      0.76      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97590795 0.97947425 0.97841727 0.97804966 0.97876934]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      1701\n",
      "           1       0.75      0.77      0.76       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.85      0.86      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 70\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.80      0.74      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97198276 0.98018018 0.98124098 0.9738445  0.97560976]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      1701\n",
      "           1       0.76      0.77      0.76       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 71\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.79      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.88      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97731365 0.97912167 0.97666068 0.9748924  0.97947425]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1701\n",
      "           1       0.77      0.82      0.80       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.89      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 72\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.73      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97619048 0.97386323 0.97841727 0.97910663 0.97947425]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.77      0.81      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.88      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 73\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1701\n",
      "           1       0.85      0.77      0.81       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.87      0.89      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97619048 0.97631012 0.98159509 0.97875405 0.97525995]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.81      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 74\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.75      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.86      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97692862 0.97491039 0.98230408 0.97594255 0.97212294]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.78      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 75\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1701\n",
      "           1       0.86      0.72      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.91      0.85      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97697842 0.97947425 0.97912167 0.9738445  0.97701149]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.72      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 76\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.75      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.86      0.88      2026\n",
      "weighted avg       0.93      0.94      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97627606 0.97456109 0.97771387 0.97945946 0.97351467]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.80      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.88      0.88      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 77\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.73      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97655968 0.97701149 0.97771387 0.97910663 0.97736256]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.77      0.77      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 78\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.80      0.74      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97837058 0.97560976 0.9724705  0.98122744 0.97806544]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1701\n",
      "           1       0.76      0.76      0.76       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 79\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1701\n",
      "           1       0.82      0.68      0.74       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.88      0.83      0.85      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.96987088 0.97947425 0.97736256 0.98264642 0.98159509]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.78      0.75      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 80\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.73      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.98015157 0.97631012 0.97701149 0.97631012 0.97769784]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.78      0.78      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 81\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.72      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.85      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97837058 0.97876934 0.97525995 0.97279885 0.97595981]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.82      0.77      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 82\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.80      0.74      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97553957 0.98301409 0.97736256 0.97841727 0.97279885]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.77      0.77      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.86      0.86      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 83\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.73      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97452458 0.98265896 0.97386323 0.97699497 0.98018018]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.78      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 84\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.79      0.74      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.97797039 0.97736256 0.98053353 0.98016589 0.98018018]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.77      0.80      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.88      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 85\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.74      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.86      0.87      2026\n",
      "weighted avg       0.93      0.94      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97696184 0.97595981 0.97631012 0.97559225 0.97912167]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.78      0.79      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 86\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.82      0.72      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.85      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97803385 0.98088713 0.97982709 0.9752422  0.97631012]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.82      0.78      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 87\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1701\n",
      "           1       0.83      0.70      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.98114576 0.97736256 0.97560976 0.97912167 0.97804966]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.80      0.75      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 88\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.85      0.73      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.85      0.87      2026\n",
      "weighted avg       0.93      0.94      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97480202 0.97666068 0.97947425 0.97594255 0.97841727]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.79      0.76      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 89\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1701\n",
      "           1       0.81      0.70      0.75       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.83      0.85      2026\n",
      "weighted avg       0.92      0.93      0.92      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97692862 0.98230408 0.98124098 0.97175545 0.97701149]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.78      0.74      0.76       325\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.86      0.85      0.86      2026\n",
      "weighted avg       0.92      0.92      0.92      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 90\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1701\n",
      "           1       0.83      0.69      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.83      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.9772481  0.97666068 0.97491039 0.98016589 0.97876934]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.80      0.75      0.77       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 91\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1701\n",
      "           1       0.84      0.70      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97338129 0.97421203 0.98018018 0.97840173 0.98088713]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.81      0.77      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 92\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.83      0.77      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97768179 0.97841727 0.97281831 0.97875405 0.97491039]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.78      0.78      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 93\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1701\n",
      "           1       0.84      0.70      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.84      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97909156 0.97666068 0.97631012 0.97594255 0.97806544]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      1701\n",
      "           1       0.79      0.73      0.76       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.85      0.86      2026\n",
      "weighted avg       0.92      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 94\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.81      0.76      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.9762931  0.97841727 0.97947425 0.97806544 0.97594255]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1701\n",
      "           1       0.77      0.81      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.88      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 95\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1701\n",
      "           1       0.84      0.79      0.82       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.88      0.89      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.971715   0.97736256 0.97525995 0.9738445  0.98230408]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.80      0.80       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.88      0.88      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 96\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.84      0.74      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.90      0.86      0.87      2026\n",
      "weighted avg       0.93      0.94      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Cross Val Score : [0.9740447  0.97701149 0.98018018 0.97699497 0.97281831]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.79      0.78      0.78       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 97\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.82      0.77      0.80       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97589061 0.97806544 0.97982709 0.97875405 0.97525995]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1701\n",
      "           1       0.80      0.78      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.88      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 98\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.75      0.79       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.89      0.86      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Cross Val Score : [0.97515304 0.97666068 0.98053353 0.9752422  0.97491039]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1701\n",
      "           1       0.82      0.77      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.93      0.94      0.94      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " random_state = 99\n",
      "XGBoost ========== Default\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1701\n",
      "           1       0.83      0.76      0.79       325\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.89      0.87      0.88      2026\n",
      "weighted avg       0.93      0.94      0.94      2026\n",
      "\n",
      "\n",
      "==============================\n",
      "\n",
      "\n",
      "GridSearchCV Search Best Params for XGBoost..............................\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      ">>>> Best Parameters for XGBoost\n",
      "{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Cross Val Score : [0.97097814 0.97806544 0.97806544 0.97804966 0.97947425]\n",
      "XGBoost ========== Optimization Param\n",
      "\n",
      ">>>> Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1701\n",
      "           1       0.78      0.82      0.80       325\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.89      0.88      2026\n",
      "weighted avg       0.94      0.93      0.93      2026\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = bank_df.drop(columns=['Attrition_Flag'])\n",
    "y = bank_df['Attrition_Flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)\n",
    "\n",
    "    #####################\n",
    "\n",
    "    # 스케일링\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # 모델 선정\n",
    "    models = {\n",
    "        # \"Logistic Regression\": LogisticRegression(random_state=random_state),\n",
    "        # \"Random Forest\": RandomForestClassifier(random_state=random_state),\n",
    "        \"XGBoost\": XGBClassifier(random_state=random_state),\n",
    "        # \"LightGBM\" : LGBMClassifier(random_state=random_state)\n",
    "    }\n",
    "\n",
    "    # 모델 학습 및 평가\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)    \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]  # ROC-AUC 계산을 위한 확률값\n",
    "        \n",
    "        # 평가 지표 출력\n",
    "        print(f\"{name} ========== Default\")\n",
    "        # print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        # print(f\"Precision : {precision_score(y_test, y_pred):.4f}\")\n",
    "        # print(f\"Recall : {recall_score(y_test, y_pred):.4f}\")\n",
    "        # print(f\"F1 Score : {f1_score(y_test, y_pred):.4f}\")\n",
    "        # print(f\"ROC-AUC : {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "        print(f\"\\n>>>> Classification Report\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "        # 특성 중요도 확인\n",
    "        # if (name == 'Logistic Regression'):\n",
    "        #     coef_importance = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_[0]})\n",
    "        #     print(\"\\n>>>> Feature Coefficients\\n\", coef_importance.sort_values(by='Coefficient', ascending=False))\n",
    "        # else:\n",
    "        # feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': model.feature_importances_})\n",
    "        # print(\"\\n>>>> Feature Importance\\n\", feature_importance.sort_values(by='Importance', ascending=False))\n",
    "\n",
    "        print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "    # 오버샘플링 적용 (평균기준)\n",
    "    # 복제, 생성, \n",
    "    smote = RandomOverSampler(random_state=random_state)\n",
    "    X_train_resample, y_train_resample = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 선정\n",
    "    models = {\n",
    "        # \"Logistic Regression\": LogisticRegression(random_state=random_state),\n",
    "        # \"Random Forest\": RandomForestClassifier(random_state=random_state),\n",
    "        \"XGBoost\": XGBClassifier(random_state=random_state),\n",
    "        # \"LightGBM\" : LGBMClassifier(random_state=random_state)\n",
    "    }\n",
    "\n",
    "    # 파라미터 설정\n",
    "    param_grids = {\n",
    "        # \"Logistic Regression\": {\n",
    "        #     'C': [0.01, 0.1, 1, 10],              # 규제 강도\n",
    "        #     'penalty': ['l1', 'l2'],               # 규제 유형\n",
    "        #     'solver': ['liblinear']                # l1과 l2 모두 지원하는 solver\n",
    "        # },\n",
    "        \"Random Forest\": {\n",
    "            'n_estimators': [50, 100, 200],                 # 트리 개수\n",
    "            'max_depth': [3, 5],                          # 최대 깊이\n",
    "            'min_samples_split': [2, 5, 10],                # 노드 분할 최소 샘플 : 값이 클수록 트리가 덜 복잡해져 과적합을 줄이는 효과\n",
    "            'min_samples_leaf': [1, 2, 4],                  # 리프 노드 최소 샘플 : 값이 크면 모델이 단순 (클래스 불균형이 심하면 크게 설정)\n",
    "            'max_features': ['sqrt', 'log2', 0.3, 0.5],     # 특성 샘플링 비율 : 각 트리에서 사용할 특성의 최대 개수 (무작위성을 높여 모델의 다양성을 증가)\n",
    "            'class_weight' : ['balanced']                   # 클래스 가중치 : 클래스 불균형을 해결하기 위해 클래스에 가중치를 부여\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            'n_estimators': [50, 100, 200],                 # 트리 개수\n",
    "            'max_depth': [1, 3, 5, 10],                     # 최대 깊이 : XGBoost는 깊이가 얕아도 잘 작동한다!\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.3],        # 학습률\n",
    "            'subsample': [0.6, 0.8, 1.0],                   # 각 트리 학습에 사용할 데이터 샘플 비율 : 값이 낮을수록 과적합 방지\n",
    "        },\n",
    "        \"LightGBM\": {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [2, 5, 10],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "            'num_leaves': [20, 31, 50],                     # 한 트리의 최대 리프 노드 수 : 2^(max_depth)보다 작아야 과적합을 줄이는 데 유리\n",
    "            'reg_lambda' : [0.1, 1.0]                       # L2 규제 : 과적합을 방지하고 모델을 안정화\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # 모델 학습 및 평가\n",
    "    for name, model in models.items():\n",
    "        # 파라미터 학습\n",
    "        print(f\"\\nGridSearchCV Search Best Params for {name}..............................\")\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "        grid_search.fit(X_train_resample, y_train_resample)\n",
    "        \n",
    "        # 최적 모델 선정\n",
    "        best_model = grid_search.best_estimator_    \n",
    "        print(f\">>>> Best Parameters for {name}\\n{grid_search.best_params_}\")\n",
    "        \n",
    "        # 교차 검증\n",
    "        print(f\"Cross Val Score : {cross_val_score(best_model, X_train_resample, y_train_resample, scoring='f1', cv=5)}\")\n",
    "\n",
    "        # 예측\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # ROC-AUC 계산을 위한 확률값\n",
    "        \n",
    "        # 평가 지표 출력\n",
    "        print(f\"{name} ========== Optimization Param\")\n",
    "        # print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        # print(f\"Precision : {precision_score(y_test, y_pred):.4f}\")\n",
    "        # print(f\"Recall : {recall_score(y_test, y_pred):.4f}\")\n",
    "        # print(f\"F1 Score : {f1_score(y_test, y_pred):.4f}\")\n",
    "        # print(f\"ROC-AUC : {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "        print(f\"\\n>>>> Classification Report\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "        # 특성 중요도 확인\n",
    "        # if (name == \"Logistic Regression\"):\n",
    "        #     coef_importance = pd.DataFrame({'Feature': X.columns, 'Coefficient': best_model.coef_[0]})\n",
    "        #     print(\"\\n>>>> Feature Coefficients\\n\", coef_importance.sort_values(by='Coefficient', ascending=False))\n",
    "        # else:\n",
    "        # feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': best_model.feature_importances_})\n",
    "        # print(\"\\n>>>> Feature Importance\\n\", feature_importance.sort_values(by='Importance', ascending=False))\n",
    "\n",
    "        print(\"\\n\" + \"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 스케일링\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 선정\n",
    "# models = {\n",
    "#     # \"Logistic Regression\": LogisticRegression(random_state=random_state),\n",
    "#     # \"Random Forest\": RandomForestClassifier(random_state=random_state),\n",
    "#     \"XGBoost\": XGBClassifier(random_state=random_state),\n",
    "#     # \"LightGBM\" : LGBMClassifier(random_state=random_state)\n",
    "# }\n",
    "\n",
    "# # 모델 학습 및 평가\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train, y_train)    \n",
    "#     y_pred = model.predict(X_test)\n",
    "#     y_pred_proba = model.predict_proba(X_test)[:, 1]  # ROC-AUC 계산을 위한 확률값\n",
    "    \n",
    "#     # 평가 지표 출력\n",
    "#     print(f\"{name} ==========\")\n",
    "#     print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "#     print(f\"Precision : {precision_score(y_test, y_pred):.4f}\")\n",
    "#     print(f\"Recall : {recall_score(y_test, y_pred):.4f}\")\n",
    "#     print(f\"F1 Score : {f1_score(y_test, y_pred):.4f}\")\n",
    "#     print(f\"ROC-AUC : {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "#     print(f\"\\n>>>> Classification Report\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "#     # 특성 중요도 확인\n",
    "#     # if (name == 'Logistic Regression'):\n",
    "#     #     coef_importance = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_[0]})\n",
    "#     #     print(\"\\n>>>> Feature Coefficients\\n\", coef_importance.sort_values(by='Coefficient', ascending=False))\n",
    "#     # else:\n",
    "#     feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': model.feature_importances_})\n",
    "#     print(\"\\n>>>> Feature Importance\\n\", feature_importance.sort_values(by='Importance', ascending=False))\n",
    "\n",
    "#     print(\"\\n\" + \"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 오버 샘플링 및 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 오버샘플링 적용 (평균기준)\n",
    "# # 복제, 생성, \n",
    "# smote = RandomOverSampler(random_state=random_state)\n",
    "# X_train_resample, y_train_resample = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# # 모델 선정\n",
    "# models = {\n",
    "#     # \"Logistic Regression\": LogisticRegression(random_state=random_state),\n",
    "#     # \"Random Forest\": RandomForestClassifier(random_state=random_state),\n",
    "#     \"XGBoost\": XGBClassifier(random_state=random_state),\n",
    "#     # \"LightGBM\" : LGBMClassifier(random_state=random_state)\n",
    "# }\n",
    "\n",
    "# # 파라미터 설정\n",
    "# param_grids = {\n",
    "#     # \"Logistic Regression\": {\n",
    "#     #     'C': [0.01, 0.1, 1, 10],              # 규제 강도\n",
    "#     #     'penalty': ['l1', 'l2'],               # 규제 유형\n",
    "#     #     'solver': ['liblinear']                # l1과 l2 모두 지원하는 solver\n",
    "#     # },\n",
    "#     \"Random Forest\": {\n",
    "#         'n_estimators': [50, 100, 200],                 # 트리 개수\n",
    "#         'max_depth': [3, 5],                          # 최대 깊이\n",
    "#         'min_samples_split': [2, 5, 10],                # 노드 분할 최소 샘플 : 값이 클수록 트리가 덜 복잡해져 과적합을 줄이는 효과\n",
    "#         'min_samples_leaf': [1, 2, 4],                  # 리프 노드 최소 샘플 : 값이 크면 모델이 단순 (클래스 불균형이 심하면 크게 설정)\n",
    "#         'max_features': ['sqrt', 'log2', 0.3, 0.5],     # 특성 샘플링 비율 : 각 트리에서 사용할 특성의 최대 개수 (무작위성을 높여 모델의 다양성을 증가)\n",
    "#         'class_weight' : ['balanced']                   # 클래스 가중치 : 클래스 불균형을 해결하기 위해 클래스에 가중치를 부여\n",
    "#     },\n",
    "#     \"XGBoost\": {\n",
    "#         'n_estimators': [50, 100, 200],                 # 트리 개수\n",
    "#         'max_depth': [1, 3, 5, 10],                            # 최대 깊이 : XGBoost는 깊이가 얕아도 잘 작동한다!\n",
    "#         'learning_rate': [0.01, 0.05, 0.1, 0.3],        # 학습률\n",
    "#         'subsample': [0.6, 0.8, 1.0],                   # 각 트리 학습에 사용할 데이터 샘플 비율 : 값이 낮을수록 과적합 방지\n",
    "#     },\n",
    "#     \"LightGBM\": {\n",
    "#         'n_estimators': [50, 100, 200],\n",
    "#         'max_depth': [2, 5, 10],\n",
    "#         'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "#         'num_leaves': [20, 31, 50],                     # 한 트리의 최대 리프 노드 수 : 2^(max_depth)보다 작아야 과적합을 줄이는 데 유리\n",
    "#         'reg_lambda' : [0.1, 1.0]                       # L2 규제 : 과적합을 방지하고 모델을 안정화\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # 모델 학습 및 평가\n",
    "# for name, model in models.items():\n",
    "#     # 파라미터 학습\n",
    "#     print(f\"\\nGridSearchCV Search Best Params for {name}..............................\")\n",
    "#     grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "#     grid_search.fit(X_train_resample, y_train_resample)\n",
    "    \n",
    "#     # 최적 모델 선정\n",
    "#     best_model = grid_search.best_estimator_    \n",
    "#     print(f\">>>> Best Parameters for {name}\\n{grid_search.best_params_}\")\n",
    "    \n",
    "#     # 교차 검증\n",
    "#     print(f\"Cross Val Score : {cross_val_score(best_model, X_train_resample, y_train_resample, scoring='f1', cv=5)}\")\n",
    "\n",
    "#     # 예측\n",
    "#     y_pred = best_model.predict(X_test)\n",
    "#     y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # ROC-AUC 계산을 위한 확률값\n",
    "    \n",
    "#     # 평가 지표 출력\n",
    "#     print(f\"{name} ==========\")\n",
    "#     print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "#     print(f\"Precision : {precision_score(y_test, y_pred):.4f}\")\n",
    "#     print(f\"Recall : {recall_score(y_test, y_pred):.4f}\")\n",
    "#     print(f\"F1 Score : {f1_score(y_test, y_pred):.4f}\")\n",
    "#     print(f\"ROC-AUC : {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "#     print(f\"\\n>>>> Classification Report\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "#     # 특성 중요도 확인\n",
    "#     # if (name == \"Logistic Regression\"):\n",
    "#     #     coef_importance = pd.DataFrame({'Feature': X.columns, 'Coefficient': best_model.coef_[0]})\n",
    "#     #     print(\"\\n>>>> Feature Coefficients\\n\", coef_importance.sort_values(by='Coefficient', ascending=False))\n",
    "#     # else:\n",
    "#     feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': best_model.feature_importances_})\n",
    "#     print(\"\\n>>>> Feature Importance\\n\", feature_importance.sort_values(by='Importance', ascending=False))\n",
    "\n",
    "#     print(\"\\n\" + \"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 모델 선정 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(model, \"model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
